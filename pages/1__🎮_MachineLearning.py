import streamlit as st
import pandas as pd
import numpy as np
import sklearn
from sklearn.preprocessing import LabelEncoder
# æ˜¾ç¤ºæ ‡é¢˜
st.title('Titanic :blue[Machine Learning]ğŸš¢')
st.markdown("Githubå¼€æºé“¾æ¥:https://github.com/WorldBloom/Cool-Streamlit-Langchain")
# æ˜¾ç¤ºç« èŠ‚æ ‡é¢˜
st.header('é—®é¢˜çš„ç®€å•ä»‹ç»')
#ä»‹ç»æ–‡å­—
st.markdown("æ³°å¦å°¼å…‹å·Kaggleç«èµ›æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå‚ä¸è€…ä½¿ç”¨æœºå™¨å­¦ä¹ æ¥é¢„æµ‹å“ªäº›ä¹˜å®¢åœ¨æ³°å¦å°¼å…‹å·æ²‰èˆ¹äº‹æ•…ä¸­å¹¸å­˜ä¸‹æ¥ã€‚ç›®æ ‡æ˜¯å»ºç«‹ä¸€ä¸ª:blue[é¢„æµ‹æ¨¡å‹]ï¼Œé€šè¿‡ä¹˜å®¢æ•°æ®ï¼ˆå¦‚å§“åã€å¹´é¾„ã€æ€§åˆ«ã€ç¤¾ä¼šç»æµé˜¶å±‚ç­‰ï¼‰å›ç­”â€œå“ªäº›ç±»å‹çš„äººæ›´æœ‰å¯èƒ½ç”Ÿè¿˜â€çš„é—®é¢˜ã€‚æ­¤ç«èµ›è¢«è®¾è®¡ä¸ºæœºå™¨å­¦ä¹ åˆå­¦è€…çš„å…¥é—¨æŒ‘æˆ˜ã€‚æ›´å¤šç»†èŠ‚å¯ä»¥è®¿é—®[Kaggleä¸Šçš„ç«èµ›æ¦‚è§ˆ](https://www.kaggle.com/competitions/titanic/overview)-From ChatGPT")

st.header('æ•°æ®çš„è§‚å¯Ÿ')

st.markdown("ä¸‹è½½å¥½èµ›é¢˜çš„æ•°æ®åæˆ‘ä»¬åº”è¯¥è§‚å¯Ÿä¸€ä¸‹æ•°æ®å¤§ä½“çš„å½¢çŠ¶")
st.markdown("### è®­ç»ƒé›†çš„æ•°æ®")
#å¯¼å…¥è®­ç»ƒé›†æ•°æ®
st.code('''
        import pandas as pd
        df_train = pd.read_csv("titanic_data/train.csv")
        df_train   
        #df_train_head=df_train.head()å®é™…æƒ…å†µå¯ä»¥é€‰æ‹©åªçœ‹å‰å‡ ä¸ªæ•°æ®è§‚å¯Ÿå¤§æ¦‚æƒ…å†µï¼ˆé»˜è®¤ä¸ºå‰5è¡Œï¼‰
        ''', language='python')

df_train = pd.read_csv("titanic_data/train.csv")
df_train_head=df_train.head()
st.write(df_train)
st.markdown("å¯ä»¥çœ‹åˆ°ä¸€å…±æœ‰891æ¡æ•°æ®(æ²¡é”™å§890-0+1)ï¼Œä¹Ÿå°±æ˜¯ä¸€å…±æœ‰891ä¸ªä¹˜å®¢çš„æ•°æ®")
st.markdown("ä¸€ä¸ªä¹˜å®¢çš„æ•°æ®åŒ…å«äº†ä»–çš„ä¹˜å®¢ç¼–ç ï¼Œç”Ÿå­˜çŠ¶æ€ï¼Œä»“ä½ç­‰çº§ï¼Œå§“åï¼Œæ€§åˆ«ç­‰ç­‰")
st.markdown("æ•°æ®é›†åŒ…å«ä»¥ä¸‹åˆ—ï¼šPassengerIdã€`Survived`ï¼ˆç”Ÿå­˜çŠ¶æ€ï¼Œè¿™æ˜¯æˆ‘ä»¬çš„ç›®æ ‡å˜é‡ï¼‰ã€Pclassã€Nameã€Sexã€Ageã€SibSpã€Parchã€Ticketã€Fareã€Cabinå’ŒEmbarkedã€‚")
st.markdown("### æµ‹è¯•é›†çš„æ•°æ®")
#å¯¼å…¥æµ‹è¯•é›†çš„æ•°æ®
st.code('''
        df_test = pd.read_csv("titanic_data/test.csv")
        df_test   
        #df_test_head=df_test.head()
        ''', language='python')
df_test = pd.read_csv("titanic_data/test.csv")
st.write(df_test)

st.markdown("åŒæ ·çš„æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿæµ‹è¯•é›†çš„å½¢çŠ¶ï¼Œæµ‹è¯•é›†ç›¸æ¯”è®­ç»ƒé›†å°‘äº†ç”Ÿå­˜çŠ¶æ€ä¸€åˆ—çš„æ•°æ®")

#æ•°æ®å¤„ç†æ¸…æ´—
st.header('æ•°æ®å¤„ç†æ¸…æ´—')
# æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
st.markdown('### ç¼ºå¤±å€¼çš„å¤„ç†')

st.markdown("è®©æˆ‘ä»¬çš„é‡å¿ƒå›åˆ°è®­ç»ƒé›†ä¸Šæ¥ï¼Œå®é™…æˆ‘ä»¬å¯ä»¥å‘ç°æ•°æ®ä¸­æ˜¯æœ‰éå¸¸å¤šçš„ç¼ºå¤±å€¼çš„ï¼ˆä¹Ÿå°±æ˜¯é‚£äº›æ˜¾ç¤ºä¸ºNoneçš„å€¼ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹è¿™äº›æ•°æ®è¿›è¡Œå¤„ç†")

st.markdown("æˆ‘ä»¬é¦–å…ˆæ£€æŸ¥æœ‰å“ªäº›å› å­ï¼ˆç‰¹å¾ï¼‰æ˜¯æœ‰ç©ºå€¼çš„")

#------------------------------------------------------
check_missing_values_train_code = '''
missing_values_train = df_train.isnull().sum()
missing_values_train[missing_values_train > 0])
'''
st.code(check_missing_values_train_code, language='python')
#------------------------------------------------------
missing_values_train = df_train.isnull().sum()
st.write(missing_values_train[missing_values_train > 0])

st.markdown("å¯ä»¥çœ‹åˆ°ageï¼ˆå¹´é¾„ï¼‰æœ‰177ä¸ªç©ºå€¼ï¼ŒEmbarkedï¼ˆç™»èˆ¹æ¸¯å£ï¼Ÿï¼‰æœ‰2ä¸ªç©ºå€¼ï¼Œè€Œ`cabin`ï¼ˆèˆ¹èˆ±ï¼‰çš„æ•°æ®ç©ºå€¼é«˜è¾¾687ï¼")

st.markdown(
'''
æˆ‘ä»¬å†³å®šå¯¹è¿™äº›ç¼ºå¤±å€¼åšå¦‚ä¸‹çš„å¤„ç†(è¿™äº›éƒ½æ˜¯ç®€å•çš„å¤„ç†æ–¹å¼)
1. **Age**ï¼šä½¿ç”¨å¹´é¾„çš„ä¸­ä½æ•°å¡«å……ç¼ºå¤±å€¼ã€‚
2. **Cabin**ï¼šç”±äºç¼ºå¤±å€¼è¾ƒå¤šï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„ç‰¹å¾`HasCabin`è¡¨ç¤ºä¹˜å®¢æ˜¯å¦æœ‰èˆ¹èˆ±ä¿¡æ¯ï¼ˆ1ä¸ºæœ‰ï¼Œ0ä¸ºæ— ï¼‰:blue[ï¼ˆå½“ç„¶äº†ï¼Œå¤§èƒ†ç‚¹ï¼Œä½ å¯ä»¥ç›´æ¥æŠŠè¿™ä¸€åˆ—ç»™åˆ é™¤äº†ğŸ˜‚ï¼‰]
3. **Embarked**ï¼šç”±äºåªæœ‰2ä¸ªç¼ºå¤±å€¼ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æœ€é¢‘ç¹å‡ºç°çš„æ¸¯å£å¡«å……è¿™äº›ç¼ºå¤±å€¼ã€‚ï¼ˆä¹Ÿå°±æ˜¯ä¼—æ•°ï¼‰
''')


#------------------------------------------------------
st.code('''
# å¡«å…… 'Age' åˆ—ä¸­çš„ç¼ºå¤±å€¼ä¸ºä¸­ä½æ•°
df_train['Age'].fillna(df_train['Age'].median(), inplace=True)

# åŸºäº 'Cabin' ä¿¡æ¯åˆ›å»º 'HasCabin' ç‰¹å¾
df_train['HasCabin'] = df_train['Cabin'].notnull().astype(int)

# ä½¿ç”¨æœ€å¸¸è§çš„æ¸¯å£ä¿¡æ¯å¡«å…… 'Embarked' åˆ—ä¸­çš„ç¼ºå¤±å€¼
df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)
''',language='python')
df_train['Age'].fillna(df_train['Age'].median(), inplace=True)#inplace=Trueä»£è¡¨å°†æ•°æ®çœŸæ˜¯å†™å…¥dataframeä¸­
df_train['HasCabin'] = df_train['Cabin'].notnull().astype(int)
df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)
#------------------------------------------------------


st.markdown("å¥½çš„ï¼Œç°åœ¨æ•°æ®å¤„ç†å®Œäº†ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹çœ‹å¤„ç†å®Œé•¿ä»€ä¹ˆæ ·å­")
st.code("df_train",language="python")
st.write(df_train)
st.markdown("çœ‹ä¸Šå»ä¸é”™ï¼Œæ•°æ®è¢«å¡«å……äº†ï¼Œä¹Ÿæ–°å¢åŠ äº†HasCabinè¿™ä¸€åˆ—")
st.markdown("æˆ‘ä»¬å¯ä»¥å†æ¬¡ä½¿ç”¨å‰é¢çš„ä»£ç æ£€æŸ¥ä¸€ä¸‹æ˜¯å¦è¿˜æœ‰ç©ºå€¼")
check_missing_values_train_code = '''
missing_values_train = df_train.isnull().sum()
missing_values_train[missing_values_train > 0])
'''
missing_values_train = df_train.isnull().sum()
st.write(missing_values_train[missing_values_train > 0])
st.markdown("å¯ä»¥çœ‹åˆ°`cabin`è¿˜æœ‰ç©ºå€¼ï¼Œå› ä¸ºæˆ‘ä»¬åªæ˜¯å¢åŠ äº†`HasCabin`çš„ç‰¹å¾ï¼Œå¹¶æ²¡æœ‰åˆ å»åŸæœ¬`cabin`è¿™ä¸€åˆ—ï¼Œæ²¡å…³ç³»ï¼Œæˆ‘ä»¬å¯ä»¥æ”¾åˆ°åé¢å¤„ç†ï¼ˆæŠŠä»–dropæ‰ï¼‰")

st.markdown("### æ•°æ®ç¼–ç ")
st.markdown("å¤„ç†å®Œç¼ºå¤±å€¼åæ•´ä¸ªæ•°æ®çœ‹ä¸Šå»éƒ½æŒºä¸é”™äº†ï¼Œå¥½åƒå¯ä»¥ç›´æ¥è¿›è¡Œæœºå™¨å­¦ä¹ äº†ï¼ŒButğŸ¤šï¼Œè§‚å¯Ÿå¯ä»¥å‘ç°æˆ‘ä»¬çš„æ•°æ®ä¸­æ˜¯å­˜åœ¨`å­—ç¬¦å‹`çš„æ•°æ®çš„ï¼Œè¯´äººè¯å°±æ˜¯æ–‡å­—ç±»å‹çš„æ•°æ®ï¼Œä¸æ˜¯æ•°å€¼å‹çš„æ•°æ®123456789ç­‰ç­‰")
st.markdown("æˆ‘ä»¬å†³å®šå¯¹è¾ƒä¸ºå‹å¥½çš„ç‰¹å¾æ•°æ®è¿›è¡Œç¼–ç å¤„ç†")
st.markdown("è¾ƒä¸ºå‹å¥½æŒ‡çš„æ˜¯é‚£äº›ç§ç±»å¹¶ä¸æ˜¯ç‰¹åˆ«å¤šçš„ç‰¹å¾ï¼Œæ¯”å¦‚`Sex`æ€§åˆ«ï¼Œ`Embarked`ç™»èˆ¹æ¸¯å£")
st.markdown("é‚£äº›ä¸æ˜¯å¾ˆå‹å¥½çš„æ•°æ®ä¾‹å¦‚`Name`ï¼Œ`Ticket`ç­‰ç­‰ï¼Œç§ç±»æ˜¯åœ¨å¤ªå¤šäº†ï¼ï¼ï¼Œ891ä¸ªäººçš„å§“åæˆ‘æ€»ä¸èƒ½ç¼–891ä¸ªå·ï¼Œé‚£æ ·å¥½åƒæ²¡å•¥æ„ä¹‰")
st.code('''
from sklearn.preprocessing import LabelEncoder#è¿™é‡Œéœ€è¦å¯¼å…¥é¢å¤–çš„åº“
# å®ä¾‹åŒ– LabelEncoder
# å¯¹ 'Sex' åˆ—è¿›è¡Œç¼–ç 
label_encoder_sex = LabelEncoder()
df_train['Sex'] = label_encoder_sex.fit_transform(df_train['Sex'])
# å¯¹ 'Embarked' åˆ—è¿›è¡Œç¼–ç ï¼Œå…ˆå¡«å……ç¼ºå¤±å€¼
df_train['Embarked'].fillna('S', inplace=True)#Sæ˜¯æœ€å¸¸è§çš„æ¸¯å£
label_encoder_embarked = LabelEncoder()
df_train['Embarked'] = label_encoder_embarked.fit_transform(df_train['Embarked'])
        ''')
# å®ä¾‹åŒ– LabelEncoder
# å¯¹ 'Sex' åˆ—è¿›è¡Œç¼–ç 
label_encoder_sex = LabelEncoder()
df_train['Sex'] = label_encoder_sex.fit_transform(df_train['Sex'])
# å¯¹ 'Embarked' åˆ—è¿›è¡Œç¼–ç ï¼Œå…ˆå¡«å……ç¼ºå¤±å€¼
df_train['Embarked'].fillna('S', inplace=True)#Sæ˜¯æœ€å¸¸è§çš„æ¸¯å£
label_encoder_embarked = LabelEncoder()
df_train['Embarked'] = label_encoder_embarked.fit_transform(df_train['Embarked'])

st.write(df_train)
st.markdown("å¯ä»¥ï¼Œéå¸¸å®Œç¾ï¼Œ`Sex`è¢«ç¼–ç æˆäº†0 1ï¼Œ`Embarked`è¢«ç¼–ç æˆäº†0 1 2")

st.header("ç‰¹å¾å·¥ç¨‹")
st.markdown("### icing on the cake")

st.markdown('æˆ–è®¸ä½ æƒ³åœ¨è¿›è¡Œç¼–ç ä¹‹åæˆ‘ä»¬åŸºæœ¬å°±å¤„ç†å®Œäº†æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ä¸¢æ‰ä¸€äº›åŸºæœ¬æ²¡ä»€ä¹ˆæ„ä¹‰çš„ç‰¹å¾ï¼Œé©¬ä¸Šè¿›è¡Œæœºå™¨å­¦ä¹ çš„å¤„ç†')
st.markdown('ä½†ç”¨ä½ èªæ˜çš„è„‘è¢‹ç“œæƒ³ä¸€æƒ³ï¼Œå®é™…ä¸Šæˆ‘ä»¬å¯ä»¥æ ¹æ®è¿™äº›æ²¡ä»€ä¹ˆæ„ä¹‰çš„ç‰¹å¾`åˆ›é€ `å‡ºä¸€äº›æœ‰æ„ä¹‰çš„ç‰¹å¾ï¼Œè¿™æˆ–è®¸æœ‰åŠ©äºæå‡æœºå™¨å­¦ä¹ çš„æ€§èƒ½')
st.markdown('è®©æˆ‘ä»¬å›åˆ°kaggleèµ›é¢˜é¡µé¢ï¼Œåœ¨[Dataä¸€é¡µ](https://www.kaggle.com/competitions/titanic/data)çš„è¯´æ˜ä¸­ã€‚æ‰€æœ‰å˜é‡çš„è¯¦ç»†è¯´æ˜éƒ½åœ¨è¿™é‡Œ')

# åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ¯åˆ—çš„ç›¸å¯¹å®½åº¦
col1, col2 = st.columns([2, 1])  # ä½ å¯ä»¥è°ƒæ•´è¿™é‡Œçš„æ•°å­—æ¥æ”¹å˜åˆ—çš„ç›¸å¯¹å®½åº¦
with col1:  # ä½¿ç”¨withè¯­å¥æŒ‡å®šæ¥ä¸‹æ¥çš„å†…å®¹åº”è¯¥æ”¾åœ¨å“ªä¸€åˆ—
    st.markdown('''
    **å˜é‡è¯´æ˜ï¼š**

    - **pclass**ï¼šç¤¾ä¼šç»æµåœ°ä½ï¼ˆSESï¼‰çš„ä»£ç†æŒ‡æ ‡
        - 1st = ä¸Šå±‚
        - 2nd = ä¸­å±‚
        - 3rd = ä¸‹å±‚
    - **age**ï¼šå¹´é¾„ï¼Œå¦‚æœå°äº1å²åˆ™ä¸ºå°æ•°ã€‚å¦‚æœå¹´é¾„æ˜¯ä¼°è®¡çš„ï¼Œä»¥xx.5çš„å½¢å¼è¡¨ç¤º
    - **sibsp**ï¼šæ•°æ®é›†ä»¥è¿™ç§æ–¹å¼å®šä¹‰å®¶åº­å…³ç³»...
        - å…„å¼Ÿå§å¦¹ = å…„å¼Ÿã€å§å¦¹ã€ç»§å…„ã€ç»§å§
        - é…å¶ = ä¸ˆå¤«ã€å¦»å­ï¼ˆæƒ…å¦‡å’Œæœªå©šå¤«è¢«å¿½ç•¥ï¼‰ï¼ˆå¯ä»¥ï¼Œå¾ˆç‚¸è£‚ï¼‰
        - sibspå…¶å®å°±æ˜¯Sibling å’Œ Spouse åˆä½“ï¼Œå¤§å®¶å¯ä»¥è‡ªå·±å»çœ‹åŸé¡µé¢
    - **parch**ï¼šæ•°æ®é›†ä»¥è¿™ç§æ–¹å¼å®šä¹‰å®¶åº­å…³ç³»...
        - çˆ¶æ¯ = æ¯äº²ã€çˆ¶äº²
        - å­å¥³ = å¥³å„¿ã€å„¿å­ã€ç»§å¥³ã€ç»§å­
        - æœ‰äº›å„¿ç«¥åªæ˜¯å’Œä¿å§†ä¸€èµ·æ—…è¡Œï¼Œå› æ­¤å¯¹ä»–ä»¬æ¥è¯´parch=0ã€‚
    ''')
with col2:
    # ä½¿ç”¨emptyæ¥åˆ›å»ºä¸Šæ–¹çš„ç©ºç™½åŒºåŸŸ
    for _ in range(7):  # è¿™é‡Œçš„æ•°å­—10å¯ä»¥æ ¹æ®éœ€è¦å¢åŠ æˆ–å‡å°‘
        st.markdown("<br>", unsafe_allow_html=True)
    # è®¾ç½®å›¾ç‰‡ä½ç½®ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç©ºç™½åŒºåŸŸçš„é«˜åº¦ä»¥è¾¾åˆ°å±…ä¸­æ•ˆæœ
    st.image('imageandvoice/cat3.png', width=250)
    # ä½¿ç”¨emptyæ¥åˆ›å»ºä¸‹æ–¹çš„ç©ºç™½åŒºåŸŸ



st.markdown('åŸºäºSibSpå’ŒParchæˆ‘ä»¬å¯ä»¥FamilySizeå’ŒIsAloneç‰¹å¾,è¡¨ç¤ºæŸä¸ªä¹˜å®¢çš„å®¶åº­å¤§å° ä¸ æ˜¯å¦ç‹¬èº«ä¸€äºº')
st.code('''
# åˆ›å»º 'FamilySize' ç‰¹å¾
df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1# åŠ 1æ˜¯å› ä¸ºè¿˜æœ‰è‡ªå·±å˜›
# åˆ›å»º 'IsAlone' ç‰¹å¾
df_train['IsAlone'] = 0
df_train.loc[df_train['FamilySize'] == 1, 'IsAlone'] = 1
''',language='python')
# åˆ›å»º 'FamilySize' ç‰¹å¾
df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1# åŠ 1æ˜¯å› ä¸ºè¿˜æœ‰è‡ªå·±å˜›
# åˆ›å»º 'IsAlone' ç‰¹å¾
df_train['IsAlone'] = 0
df_train.loc[df_train['FamilySize'] == 1, 'IsAlone'] = 1

st.markdown("### åˆ é™¤ä¸å¿…è¦çš„åˆ—")
st.code("df_train.drop(['Cabin', 'Ticket', 'Name', 'PassengerId'], axis=1, inplace=True #cabinåœ¨è¿™é‡Œå°±è¢«åˆ é™¤äº†",language='python')
# åˆ é™¤å¯èƒ½å¯¹æ¨¡å‹ä¸å¤ªæœ‰ç”¨çš„åˆ—
df_train.drop(['Cabin', 'Ticket', 'Name', 'PassengerId'], axis=1, inplace=True)
st.markdown('OK,ç°åœ¨çš„æ•°æ®çœ‹ä¸Šå»å°±éå¸¸å®Œç¾äº†ï¼')
df_train

st.header('æœºå™¨å­¦ä¹ ')
st.markdown('åœ¨è¿›è¡Œå®Œè®­ç»ƒé›†çš„æµ‹è¯•åæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹è¿›è¡Œæœºå™¨å­¦ä¹ äº†ï¼')
st.markdown(':blue[ä»£ç å…¶å®å¾ˆç®€å•ï¼å¤§å®¶é‡åœ¨ç†è§£]')

st.code('''
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# å®šä¹‰ç‰¹å¾å’Œç›®æ ‡å˜é‡
X = df_train.drop('Survived', axis=1)  # ä»è®­ç»ƒæ•°æ®ä¸­é™¤å»'Survived'åˆ—ï¼Œå‰©ä¸‹çš„ç”¨ä½œç‰¹å¾
y = df_train['Survived']  # å°†'Survived'åˆ—ç”¨ä½œç›®æ ‡å˜é‡

# å°†æ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# åˆå§‹åŒ–éšæœºæ£®æ—åˆ†ç±»å™¨
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# è®­ç»ƒæ¨¡å‹
rf_classifier.fit(X_train, y_train)

# åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹
y_pred = rf_classifier.predict(X_val)

# è®¡ç®—å‡†ç¡®ç‡
accuracy = accuracy_score(y_val, y_pred)
print("éšæœºæ£®æ—æ¨¡å‹çš„å‡†ç¡®ç‡æ˜¯:",accuracy)  # è¾“å‡ºå‡†ç¡®ç‡

        ''',language='python')

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# å®šä¹‰ç‰¹å¾å’Œç›®æ ‡å˜é‡
X = df_train.drop('Survived', axis=1)  # ä»è®­ç»ƒæ•°æ®ä¸­é™¤å»'Survived'åˆ—ï¼Œå‰©ä¸‹çš„ç”¨ä½œç‰¹å¾
y = df_train['Survived']  # å°†'Survived'åˆ—ç”¨ä½œç›®æ ‡å˜é‡

# å°†æ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# åˆå§‹åŒ–éšæœºæ£®æ—åˆ†ç±»å™¨
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# è®­ç»ƒæ¨¡å‹
rf_classifier.fit(X_train, y_train)

# åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹
y_pred = rf_classifier.predict(X_val)

# è®¡ç®—å‡†ç¡®ç‡
accuracy = accuracy_score(y_val, y_pred)

st.write("### éšæœºæ£®æ—æ¨¡å‹çš„å‡†ç¡®ç‡æ˜¯:",accuracy)
st.markdown("éšæœºæ£®æ—æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å‡†ç¡®ç‡ä¸ºçº¦80.45%!è¿™æ˜¯ä¸€ä¸ªéå¸¸ä¸é”™çš„çš„åˆå§‹ç»“æœ!ğŸ‘ğŸ‘ğŸ‘")





st.markdown('''
ä¸€äº›è¯´æ˜ï¼ˆChatä¸€ä¸‹ï¼Œä½ å°±çŸ¥é“ï¼‰

1. **å¯¼å…¥å¿…è¦çš„åº“å’Œå‡½æ•°**ï¼šä»£ç å¼€å§‹äºå¯¼å…¥`train_test_split`å‡½æ•°ç”¨äºæ•°æ®åˆ†å‰²ï¼Œ`RandomForestClassifier`ç”¨äºæ„å»ºéšæœºæ£®æ—æ¨¡å‹ï¼Œä»¥åŠ`accuracy_score`ç”¨äºè®¡ç®—é¢„æµ‹å‡†ç¡®ç‡ã€‚

2. **å®šä¹‰ç‰¹å¾å’Œç›®æ ‡å˜é‡**ï¼šä»`df_train`æ•°æ®å¸§ä¸­åˆ†ç¦»å‡ºç‰¹å¾ï¼ˆ`X`ï¼‰å’Œç›®æ ‡å˜é‡ï¼ˆ`y`ï¼‰ã€‚ç‰¹å¾åŒ…æ‹¬äº†é™¤äº†`Survived`åˆ—ä¹‹å¤–çš„æ‰€æœ‰åˆ—ï¼Œè€Œ`Survived`åˆ—æ˜¯ä½œä¸ºç›®æ ‡å˜é‡ã€‚

3. **åˆ†å‰²æ•°æ®ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†**ï¼šä½¿ç”¨`train_test_split`å‡½æ•°å°†æ•°æ®éšæœºåˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå…¶ä¸­éªŒè¯é›†å æ€»æ•°æ®çš„20%ã€‚

4. **åˆå§‹åŒ–éšæœºæ£®æ—åˆ†ç±»å™¨**ï¼šåˆ›å»ºä¸€ä¸ªéšæœºæ£®æ—åˆ†ç±»å™¨å®ä¾‹ï¼ŒæŒ‡å®šæ ‘çš„æ•°é‡ä¸º100ï¼Œå¹¶è®¾ç½®éšæœºçŠ¶æ€ä»¥ç¡®ä¿ç»“æœçš„å¯é‡å¤æ€§ã€‚

5. **è®­ç»ƒæ¨¡å‹**ï¼šä½¿ç”¨è®­ç»ƒæ•°æ®ï¼ˆç‰¹å¾å’Œç›®æ ‡å˜é‡ï¼‰è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨ã€‚

6. **åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹**ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹åœ¨éªŒè¯é›†çš„ç‰¹å¾ä¸Šè¿›è¡Œé¢„æµ‹ã€‚

7. **è®¡ç®—å‡†ç¡®ç‡**ï¼šé€šè¿‡æ¯”è¾ƒéªŒè¯é›†çš„çœŸå®ç›®æ ‡å˜é‡å’Œæ¨¡å‹é¢„æµ‹ç»“æœæ¥è®¡ç®—å‡†ç¡®ç‡ã€‚
            ''')



##å…¶ä»–æ¨¡å‹çš„é€‰æ‹©ä¸å¯è§†åŒ–
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier

# å‡è®¾df_trainæ˜¯å·²ç»åŠ è½½è¿›æ¥çš„Pandas DataFrame
# è¿™é‡Œç”¨éšæœºæ•°æ®ç”Ÿæˆä¸€ä¸ªç¤ºä¾‹DataFrame
# ä½ åº”è¯¥ç”¨å®é™…çš„æ•°æ®æ›¿æ¢è¿™ä¸€éƒ¨åˆ†
# Streamlitåº”ç”¨å¼€å§‹
st.markdown('### ä¸åŒæ¨¡å‹çš„é¢„æµ‹æ•ˆæœ')
st.markdown('å½“ç„¶äº†ï¼Œä½ å®Œå…¨å¯ä»¥é€‰æ‹©ä¸åŒçš„æ¨¡å‹è¿›è¡Œè®­ç»ƒé¢„æµ‹ï¼Œä¸€åˆ‡ä¾æ®ä½ çš„å–œå¥½ä¸è®¤çŸ¥ï¼Œè¿™é‡Œ:blue[åªæä¾›ä¸åŒçš„æµ‹è¯•é€‰é¡¹]ï¼Œå…·ä½“ä»£ç ç›¸ä¿¡å¤§å®¶å¯ä»¥è‡ªå·±å†™å‡ºæ¥')
st.markdown('å½“ç„¶äº†æ¨¡å‹åŸºæœ¬éƒ½æ˜¯sklearnçš„æ¨¡å‹ï¼Œxgboostéœ€è¦é¢å¤–ä¸‹åŒ…')

# é€‰æ‹©æ¨¡å‹ç±»å‹
model_type = st.selectbox(
    'é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ç±»å‹ğŸ“',
    ('éšæœºæ£®æ—', 'é€»è¾‘å›å½’', 'æ”¯æŒå‘é‡æœº','XGBoost','å†³ç­–æ ‘','Kæœ€è¿‘é‚»','æœ´ç´ è´å¶æ–¯','æ¢¯åº¦æå‡æ ‘','AdaBoost')
)
# æ ¹æ®é€‰å®šçš„æ¨¡å‹ç±»å‹æ˜¾ç¤ºå‚æ•°è°ƒæ•´UI
if model_type == 'éšæœºæ£®æ—':
    n_estimators = st.slider('æ ‘çš„æ•°é‡', min_value=10, max_value=200, value=100)
    model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)
elif model_type == 'é€»è¾‘å›å½’':
    C = st.slider('æ­£åˆ™åŒ–å¼ºåº¦çš„å€’æ•°', min_value=0.01, max_value=1.0, value=1.0)
    model = LogisticRegression(C=C, random_state=42)
elif model_type == 'æ”¯æŒå‘é‡æœº':
    C = st.slider('æ­£åˆ™åŒ–å‚æ•°', min_value=0.01, max_value=1.0, value=1.0)
    model = SVC(C=C, probability=True, random_state=42)
elif model_type == 'XGBoost':
    max_depth = st.slider('æœ€å¤§æ ‘æ·±åº¦', min_value=3, max_value=10, value=6)
    n_estimators = st.slider('æ ‘çš„æ•°é‡', min_value=10, max_value=200, value=100)
    learning_rate = st.slider('å­¦ä¹ ç‡', min_value=0.01, max_value=0.3, value=0.1)
    model = xgb.XGBClassifier(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, random_state=42)
elif model_type == 'å†³ç­–æ ‘':
    max_depth = st.slider('æœ€å¤§æ ‘æ·±åº¦', min_value=1, max_value=10, value=3)
    model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)
elif model_type == 'Kæœ€è¿‘é‚»':
    n_neighbors = st.slider('é‚»å±…æ•°é‡', min_value=1, max_value=10, value=5)
    model = KNeighborsClassifier(n_neighbors=n_neighbors)
elif model_type == 'æœ´ç´ è´å¶æ–¯':
    model = GaussianNB()
elif model_type == 'æ¢¯åº¦æå‡æ ‘':
    n_estimators = st.slider('æ ‘çš„æ•°é‡', min_value=10, max_value=200, value=100)
    learning_rate = st.slider('å­¦ä¹ ç‡', min_value=0.01, max_value=0.3, value=0.1)
    model = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate, random_state=42)
elif model_type == 'AdaBoost':
    n_estimators = st.slider('æ ‘çš„æ•°é‡', min_value=10, max_value=200, value=50)
    learning_rate = st.slider('å­¦ä¹ ç‡', min_value=0.01, max_value=1.0, value=1.0)
    model = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate, random_state=42)

# åˆ†å‰²æ•°æ®
X = df_train.drop('Survived', axis=1)  # ä»è®­ç»ƒæ•°æ®ä¸­é™¤å»'Survived'åˆ—ï¼Œå‰©ä¸‹çš„ç”¨ä½œç‰¹å¾
y = df_train['Survived']  # å°†'Survived'åˆ—ç”¨ä½œç›®æ ‡å˜é‡
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# è®­ç»ƒæ¨¡å‹
model.fit(X_train, y_train)

# é¢„æµ‹
y_pred = model.predict(X_val)

# è®¡ç®—å‡†ç¡®ç‡
accuracy = accuracy_score(y_val, y_pred)

# æ˜¾ç¤ºå‡†ç¡®ç‡
st.write(f'### æ¨¡å‹çš„å‡†ç¡®ç‡é«˜è¾¾: `{accuracy}`')

st.header('çœŸæ­£çš„é¢„æµ‹')
st.markdown('å‰é¢çš„æœºå™¨å­¦ä¹ éƒ½æ˜¯åœ¨å¯¹è®­ç»ƒé›†è¿›è¡Œæ“ä½œï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦å°†è®­ç»ƒå¥½çš„æ¨¡å‹åº”ç”¨åˆ°æµ‹è¯•é›†ä¸Š')
st.markdown('ä¸ºäº†ä¿è¯æ•°æ®çš„æ ¼å¼ç­‰éƒ½æ˜¯å¯¹åº”çš„ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æµ‹è¯•é›†è¿›è¡Œä¸è®­ç»ƒé›†åŒæ ·çš„å¤„ç†')

st.markdown('### å¯¹æµ‹è¯•é›†æ•°æ®è¿›è¡Œå¤„ç†')

st.code('''
# åŠ è½½æµ‹è¯•æ•°æ®é›†
df_test = pd.read_csv('titanic_data/test.csv')

# ä½¿ç”¨è®­ç»ƒæ•°æ®é›†çš„ä¸­ä½æ•°å¡«å…… 'Age' å’Œ 'Fare' åˆ—çš„ç¼ºå¤±å€¼
df_test['Age'].fillna(df_train['Age'].median(), inplace=True)
df_test['Fare'].fillna(df_train['Fare'].median(), inplace=True)

# åŸºäº 'Cabin' ä¿¡æ¯åˆ›å»º 'HasCabin' ç‰¹å¾
df_test['HasCabin'] = df_test['Cabin'].notnull().astype(int)

# åˆ›å»º 'FamilySize' ç‰¹å¾
df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1

# åˆ›å»º 'IsAlone' ç‰¹å¾
df_test['IsAlone'] = 0
df_test.loc[df_test['FamilySize'] == 1, 'IsAlone'] = 1

# ç¼–ç å¤„ç†
df_test['Sex'] = label_encoder_sex.transform(df_test['Sex'])
df_test['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)
df_test['Embarked'] = label_encoder_embarked.transform(df_test['Embarked'])
        
# åˆ é™¤å¯èƒ½å¯¹æ¨¡å‹æ²¡ä»€ä¹ˆç”¨çš„åˆ—
df_test.drop(['Cabin', 'Ticket', 'Name', 'PassengerId'], axis=1, inplace=True)

        ''')

# åŠ è½½æµ‹è¯•æ•°æ®é›†
df_test = pd.read_csv('titanic_data/test.csv')
# ä½¿ç”¨è®­ç»ƒæ•°æ®é›†çš„ä¸­ä½æ•°å¡«å…… 'Age' å’Œ 'Fare' åˆ—çš„ç¼ºå¤±å€¼
df_test['Age'].fillna(df_train['Age'].median(), inplace=True)
df_test['Fare'].fillna(df_train['Fare'].median(), inplace=True)

# åŸºäº 'Cabin' ä¿¡æ¯åˆ›å»º 'HasCabin' ç‰¹å¾
df_test['HasCabin'] = df_test['Cabin'].notnull().astype(int)

# åˆ›å»º 'FamilySize' ç‰¹å¾
df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1

# åˆ›å»º 'IsAlone' ç‰¹å¾
df_test['IsAlone'] = 0
df_test.loc[df_test['FamilySize'] == 1, 'IsAlone'] = 1

# ä½¿ç”¨è®­ç»ƒé›†ä¸­æœ€å¸¸è§çš„æ¸¯å£ä¿¡æ¯å¡«å…… 'Embarked' åˆ—çš„ç¼ºå¤±å€¼
df_test['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)
df_test['Sex'] = label_encoder_sex.transform(df_test['Sex'])
df_test['Embarked'] = label_encoder_embarked.transform(df_test['Embarked'])
# åˆ é™¤å¯èƒ½å¯¹æ¨¡å‹è¾ƒå°‘å¸®åŠ©çš„åˆ—
df_test.drop(['Cabin', 'Ticket', 'Name', 'PassengerId'], axis=1, inplace=True)

# å±•ç¤ºæµ‹è¯•æ•°æ®é›†çš„å‰å‡ è¡Œä»¥éªŒè¯
df_test

st.markdown("### ä½¿ç”¨éšæœºæ£®æ—æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹")
st.code('''
# ä½¿ç”¨éšæœºæ£®æ—æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
y_pred = rf_classifier.predict(df_test)
        
# è¾“å‡ºé¢„æµ‹ç»“æœ
st.write(y_pred)
        
# å°†é¢„æµ‹ç»“æœä¿å­˜åˆ°CSVæ–‡ä»¶ä¸­ï¼Œä¿å­˜ä¸€ä¸ªåŒ…å«ä¹˜å®¢IDå’Œä»–ä»¬çš„ç”Ÿå­˜é¢„æµ‹çš„æ–‡ä»¶
# åˆ›å»ºä¸€ä¸ªDataFrameæ¥ä¿å­˜ç»“æœ
submission = pd.DataFrame({
    "PassengerId": test_df_with_ids['PassengerId'],
    "Survived": y_pred
})
        
# ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
submission.to_csv('titanic_data/titanic_predictions.csv', index=False)

        ''')
# ä½¿ç”¨éšæœºæ£®æ—æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
y_pred = rf_classifier.predict(df_test)

# å¦‚æœä½ éœ€è¦å°†é¢„æµ‹ç»“æœä¿å­˜åˆ°CSVæ–‡ä»¶ä¸­ï¼Œå‡è®¾ä½ æƒ³è¦ä¿å­˜ä¸€ä¸ªåŒ…å«ä¹˜å®¢IDå’Œä»–ä»¬çš„ç”Ÿå­˜é¢„æµ‹çš„æ–‡ä»¶
# é¦–å…ˆï¼Œé‡æ–°åŠ è½½æµ‹è¯•æ•°æ®é›†ä»¥è·å–PassengerId
test_df_with_ids = pd.read_csv('titanic_data/test.csv')
# ç¡®ä¿é¢„æµ‹ç»“æœçš„æ•°é‡ä¸ä¹˜å®¢IDçš„æ•°é‡ç›¸åŒ¹é…
assert len(y_pred) == len(test_df_with_ids), "ç»“æœçš„æ•°é‡ä¸ä¹˜å®¢IDçš„æ•°é‡ä¸åŒ¹é…"

# åˆ›å»ºä¸€ä¸ªDataFrameæ¥ä¿å­˜ç»“æœ
submission = pd.DataFrame({
    "PassengerId": test_df_with_ids['PassengerId'],
    "Survived": y_pred
})
# ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
submission.to_csv('titanic_data/titanic_predictions.csv', index=False)
st.header("é¢„æµ‹çš„ç»“æœ")
# æ˜¾ç¤ºä¿å­˜çš„æ–‡ä»¶å¤´éƒ¨ä»¥ç¡®è®¤
st.write(submission)
st.markdown("ç°åœ¨æˆ‘ä»¬å°±å¯ä»¥é¢„æµ‹å‡ºè¿™äº›äººçš„ç”Ÿå­˜çŠ¶æ€äº†ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠç»“æœäº¤åˆ°kaggleä¸Šçœ‹çœ‹ç»“æœå¦‚ä½•ğŸ˜†")
st.markdown("åœ¨kaggleèµ›é¢˜é¡µé¢å³ä¸Šè§’ç‚¹é›†Submit Predictionå³å¯æäº¤ç»“æœ")

st.image("imageandvoice/score.png",width=1200)
st.markdown("å¾ˆæ£’ï¼å¾—åˆ†æ˜¯0.75119ï¼Œè¿™æ ·çš„å¾—åˆ†åœ¨æ»šåŠ¨æ’è¡Œæ¦œä¸Šçš„æ’åå¤§çº¦åœ¨1wåå·¦å³ï¼Œä½†æ˜¯æ²¡æœ‰è¿‡1wï¼Œèƒ½å¦è¶…è¶Š1wå°±çœ‹å¤§å®¶åŠªåŠ›äº†ğŸ˜")

st.header("æ¥ç‚¹æ‹“æ‰‘")
st.markdown("æ•¬è¯·æœŸå¾…...")